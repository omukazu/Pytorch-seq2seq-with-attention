# Pytorch Seq2seq with Attention

This repository contains a sequence to sequence model with attention using Pytorch 1.1.0.

## Motivation
- Try to remove the effect of PAD symbols as much as possible

## Model
- Seq2seq with Attention

![Seq2seq](https://github.com/omukazu/Pytorch-Seq2seq-with-Attention/blob/images/image/Seq2seq.png)

- Variational Seq2seq with Attention

![Variational](https://github.com/omukazu/Pytorch-Seq2seq-with-Attention/blob/images/image/Variational.png)

These models use soft attention mechanism and score is calculated by dot product. 